# Human-Protein-Atlas-Image-Classifier
Human Protein Atlas Image Classifier for Kaggle competition using a CNN.

https://www.kaggle.com/c/human-protein-atlas-image-classification
In collaboration with Timothy Eldridge.

Competition Description:
In the Human Protein Atlas Image Classification competition, competitors are provided a train.zip, train.csv, test.zip files, and sample_submission.csv files. The train.zip and test.zip consist of 124,288 and 46,808 files of cellular images in 512x512 PNG format, respectively. The train.csv file provides the labels for each of the images in the training dataset. The sample_submission.csv is used as a template for recording and submitting the predictions on the test set. Each of the files in the training and test datasets are acquired via confocal microscopy and fall under one of the following categories: green, blue, red, or yellow filter. The green filter represents the protein of interest, blue the nucleus, red microtubules, and yellow endoplasmic reticulum. The objective of the competition is to predict protein organelle localization labels, thus the green filter is used for predicting labels, and the three remaining channels are supplementary images to help with the process. The datasets consist of 27 unique cell types and a total of 28 different possible labels, with the possibility of samples being multi labeled. Each cell sample is represented by one image from each of the four filters (green, blue, red, yellow), thus the total number of cell samples is 31,072 for the training set and 11,702 cell samples for the test set.

Pre-Processing:
For pre-processing, ImageDataGenerator from Keras, MultiLabelBinarizer from Scikit Learn, and MultilabelStratifiedKFold from iterstrat were used. For this project ImageDataGenerator was used for horizontal and vertical flips of images, but can also be used for other data augmentation methods such as rotation, adjusting zoom, and changing image brightness. The MultiLabelBinarizer was used to handle the multi labeling of samples. It takes the array of test labels for a sample and outputs a new array of length 28 where each location in the array is populated with either a 1 or 0 indicating whether that sample was labeled with the label corresponding to that location in the array. Iterative-stratification (iterstat) was created by Github user Trent-b, is compatible with Sckit-Learn, and provides cross validation for multi label datasets. This method of stratification is necessary for multi label datasets in order to preserve the label proportions of the original dataset when splitting into groups. Using this approach, the training dataset was split into a training and validation set. A traditional approach to dataset stratification would have split the training set into a new training and validation set that is not representative of the label distribution in the original training set. Altering the label distribution would have caused the model to incorrectly train on a dataset that is not homogenous with the original dataset or validation set, thus decreasing model performance on the validation and test set. The original training dataset was split into 90% belonging to the new training dataset and 10% for the validation set.

As previously mentioned, each sample consists of four images in the format of a 512x512 PNG file, giving an input shape of 512x512x4 for each sample. Based on the memory limitation of our computers and to increase processing speed, the images were reduced by a factor of 4 for each dimension, for a total 16-fold reduction, to size 128x128. The new input shape for each sample was then 128x128x4.

Baseline Model:

The baseline model used the Keras library with Tensorflow backend. It was a sequential convolutional neural network with 6 convolutional layers and based on researching how fellow competitors were approaching the competition. The kernel size for each of the convolutional layers was 3x3. The first convolutional layer had an input shape of 512x512x4 to match the size of each cell sample. At each of the hidden layers a ReLu activation function was used. The ReLu activation function was chosen for the hidden layers based on research indicating that the ReLu activation function was fitting for biological phenomenon. Dropout and max pooling layers were implemented to regularize the data. The resulting feature maps were flattened and fed into a dense layer with 28 outputs, each representing a label. A sigmoid activation function was chosen for this layer due to the need for the output to be values between 0 and 1 indicating the probability of each sample belonging to each of the 28 classes. The threshold for these values was set to 0.5, where values higher than this were interpreted as the sample being positive for the corresponding label and lower indicating that it was not. 

Model Improvements: 
Processing time was a major challenge with the baseline model. In order to decrease the processing time and memory required, dimensionality reduction was performed on the images. Each file was reduced by a factor of four to create images of 128x128. Each sample then consisted of four files of size 128x128. The dimensionality reduction increased training speed and decreased the memory usage of our hardware, allowing us to run our model on our hardware.

In our final model, we updated our evaluation metric to be in line with the competition requirement of F1 score. In addition to the F1 score, the F1 loss was calculated as well. The code to calculate F1 score and F1 loss was borrowed from Michal Haltuf. The F1 loss is significant in that it overcomes certain limitations of the F1 score. In calculating the F1 score, the predicted probability values are rounded to either 0 or 1 based on a threshold of 0.5. The F1 score is therefore not continuous nor differentiable and can not be used as the loss function. The F1 loss is similar to the F1 score, with the difference that it does not include a round operation, making the function continuous and differentiable, and allowing us to calculate the gradient. 

To improve the baseline model, we increased the number of max pooling and dropout layers to reduce the number of parameters and make feature detection invariant to scaling and orientation shifts within the model. Additionally, batch normalization was incorporated into the model as an another regularizer. Batch normalization increases the stability of a neural network by normalizing the output of a previous layer by subtracting the batch mean and dividing by the standard deviation. It adjusts and scales activation functions and can increase training speed by allowing layers to learn independently of other layers. Batch normalization also decreases covariance shift as well as reduces overfitting. The last major improvement to the model included switching from using Stochastic Gradient Descent as the optimizer to instead using the Adam optimization algorithm. The Adam optimization algorithm is unique in that it calculates individual adaptive learning rates for different parameters based on estimates of the first and second moments of the gradient. The algorithm combines Adaptive Gradient Algorithm and Root Mean Square Propagation.
